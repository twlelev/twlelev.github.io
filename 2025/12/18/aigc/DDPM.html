<hr>
<h2 id="title-DDPM核心原理与简单工程实现top-falsecover-falsetoc-truemathjax-truedate-2025-12-18-11-21-20password-summary-tags-AIGCcategories-AIGC"><a href="#title-DDPM核心原理与简单工程实现top-falsecover-falsetoc-truemathjax-truedate-2025-12-18-11-21-20password-summary-tags-AIGCcategories-AIGC" class="headerlink" title="title: DDPM核心原理与简单工程实现top: falsecover: falsetoc: truemathjax: truedate: 2025-12-18 11:21:20password:summary:tags:  - AIGCcategories:  - AIGC"></a>title: DDPM核心原理与简单工程实现<br>top: false<br>cover: false<br>toc: true<br>mathjax: true<br>date: 2025-12-18 11:21:20<br>password:<br>summary:<br>tags:<br>  - AIGC<br>categories:<br>  - AIGC</h2><h2 id="1-核心思想"><a href="#1-核心思想" class="headerlink" title="1.核心思想"></a>1.核心思想</h2><p>Diffusion 模型通过模拟分子的扩散过程，将图像逐步变成纯噪声（前向过程），然后学习一个神经网络来逆转这个过程，从噪声中还原图像（反向过程）。它本质上是一个马尔科夫链。</p>
<pre><code class="Python"># 前向过程：逐步加噪声
x_0 (原始图像) → x_1 → x_2 → ... → x_T (纯噪声)

# 反向过程：逐步去噪声  
x_T (纯噪声) → x_{T-1} → ... → x_1 → x_0 (生成图像)
</code></pre>
<h2 id="2-前向过程-加噪声"><a href="#2-前向过程-加噪声" class="headerlink" title="2.前向过程(加噪声)"></a>2.前向过程(加噪声)</h2><p>给定初始数据$x_{0}$，每一步添加少量噪声<br>$q(x_t|x_{t-1}) &#x3D; N(x_t; √(1-β_t)·x_{t-1}, β_t·I)$</p>
<p>不需要一步步加噪，可以直接从 $x_0$ 得到 $x_t$：<br>$$q(x_t|x_0) &#x3D; N(x_t; √(ᾱ_t)·x_0, (1-ᾱ_t)·I)$$<br>$$x_t &#x3D; \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, \mathbf{I})$$</p>
<p>其中$\beta_{t}$是<strong>噪声调度</strong>(noise schedule)，$ᾱ_t &#x3D; ∏(1-β_i)$是<strong>累积系数</strong></p>
<h2 id="3-反向过程-去噪声"><a href="#3-反向过程-去噪声" class="headerlink" title="3.反向过程(去噪声)"></a>3.反向过程(去噪声)</h2><p>目标是估计 $p(x_{t-1} | x_t)$。由于真实分布不可知，我们用神经网络 $\theta$ 来近似：<br>$p_θ(x_{t-1}|x_t) &#x3D; N(x_{t-1}; μ_θ(x_t, t), Σ_θ(x_t, t))$</p>
<p>反向过程为什么也可以用高斯分布建模：<br>贝叶斯定理：$q(x_{t-1}|x_t, x_0) ∝ q(x_t|x_{t-1}) * q(x_{t-1}|x_0)$<br>两个高斯的乘积仍然是高斯</p>
<h3 id="3-1-均值-mu-theta-的推导"><a href="#3-1-均值-mu-theta-的推导" class="headerlink" title="3.1 均值 $\mu_\theta$ 的推导"></a>3.1 均值 $\mu_\theta$ 的推导</h3><p>通过贝叶斯定理，在给定 $x_0$ 的条件下，后验分布 $q(x_{t-1}|x_t, x_0)$ 的均值 $\tilde{\mu}_t$ 为： $$\tilde{\mu}_t &#x3D; \frac{\sqrt{\alpha_t}(1-\bar{\alpha}*{t-1})}{1-\bar{\alpha}<em>t} x_t + \frac{\sqrt{\bar{\alpha}</em>{t-1}}\beta_t}{1-\bar{\alpha}_t} x_0$$ 代入 $x_0$ 的预测值后(由前向过程$x_0$与$x_t$和$\epsilon$，可以消掉$x_0$)，神经网络实际上只需要预测噪声 $\epsilon_\theta$： $$\mu_\theta(x_t, t) &#x3D; \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right)$$</p>
<h3 id="3-2-方差-Sigma-theta-的选择"><a href="#3-2-方差-Sigma-theta-的选择" class="headerlink" title="3.2 方差 $\Sigma_\theta$ 的选择"></a>3.2 方差 $\Sigma_\theta$ 的选择</h3><ul>
<li>__选择 1 (DDPM 原作)__：固定方差 $\sigma_t^2 &#x3D; \beta_t$ 或 $\sigma_t^2 &#x3D; \tilde{\beta}_t$。</li>
<li>__选择 2 (后验方差)__：$\tilde{\beta}<em>t &#x3D; \frac{1-\bar{\alpha}</em>{t-1}}{1-\bar{\alpha}_t} \cdot \beta_t$（训练更稳定）。</li>
<li>__选择 3 (可学习方差)__：在 Improved DDPM 中，模型也预测方差，以减少采样步数。</li>
</ul>
<p> <strong>均值 $μ_θ$ 和方差 $Σ_θ$的含义</strong><br>$μ_θ(x_t, t)$ - 预测的均值</p>
<ul>
<li>这是神经网络预测的”最可能”的 $x_{t-1}$</li>
<li>代表去噪后图像的中心估计<br>$Σ_θ(x_t, t)$ - 预测的方差</li>
<li>表示预测的不确定性</li>
<li>越大表示越不确定</li>
</ul>
<h2 id="4-训练与采样算法-Training-amp-Sampling"><a href="#4-训练与采样算法-Training-amp-Sampling" class="headerlink" title="4. 训练与采样算法 (Training &amp; Sampling)"></a>4. 训练与采样算法 (Training &amp; Sampling)</h2><h3 id="训练目标-简化"><a href="#训练目标-简化" class="headerlink" title="训练目标(简化)"></a>训练目标(简化)</h3><p>$L &#x3D; E_{t,x_0,ε}[||ε - ε_θ(x_t, t)||²]$<br>其中 $ε_θ$ 是神经网络预测的噪声</p>
<h3 id="采样步骤-Langevin-Dynamics"><a href="#采样步骤-Langevin-Dynamics" class="headerlink" title="采样步骤 (Langevin Dynamics)"></a>采样步骤 (Langevin Dynamics)</h3><ol>
<li>从 $x_T \sim \mathcal{N}(0, \mathbf{I})$ 开始。</li>
<li>循环 $t &#x3D; T, \dots, 1$：<ul>
<li>预测 $\epsilon_\theta$。</li>
<li>根据 $\mu_\theta$ 计算 $x_{t-1}$。</li>
<li>若 $t &gt; 1$，加入高斯噪声 $z \sim \mathcal{N}(0, \mathbf{I})$ 以维持随机性。</li>
</ul>
</li>
</ol>
<h2 id="5-DDPM简单工程实现"><a href="#5-DDPM简单工程实现" class="headerlink" title="5.DDPM简单工程实现"></a>5.DDPM简单工程实现</h2><pre><code class="Python">class DDPMSampler:
    def __init__(self, model, betas):
        self.model = model
        self.betas = betas
        self.alphas = 1 - betas
        self.alphas_bar = torch.cumprod(self.betas, dim=0)

    def sample(self, shape, num_steps=1000):

        &quot;&quot;&quot;完整采样流程，展示所有重参数化的应用&quot;&quot;&quot;
        x_t = torch.randn(shape)
        for t in reversed(range(num_steps)):
            # ===== 1. 利用前向重参数化关系 =====
            # 为了训练网络预测噪声
            # x_t = √ᾱ_t * x_0 + √(1-ᾱ_t) * ε

            predicted_noise = self.model(x_t, t)

            # ===== 2. 均值参数化 =====
            # 将噪声预测转换为反向过程的分布均值
            # μ = 1/√α_t * (x_t - β_t/√(1-ᾱ_t) * ε_θ)

            alpha_t = self.alphas[t]
            alpha_bar_t = self.alphas_bar[t]
            beta_t = self.betas[t]
            mean = (1 / torch.sqrt(alpha_t)) * (
                x_t - (beta_t / torch.sqrt(1 - alpha_bar_t)) * predicted_noise
            )

            # 方差（DDPM论文中的固定选择）
            if t &gt; 0:
                variance = beta_t  # 简化版
            else:
                variance = 0      
                
            # ===== 3. 采样重参数化 =====
            # 从 N(mean, variance) 采样
            if t &gt; 0:
                noise = torch.randn_like(x_t)
                 x_t = mean + torch.sqrt(variance) * noise
            else:
                 x_t = mean
            return x_t


def train_diffusion_model(model, dataloader, num_epochs):
    &quot;&quot;&quot;
    展示前向重参数化在训练中的作用
    &quot;&quot;&quot;
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

    for epoch in range(num_epochs):
        for batch_idx, x_0 in enumerate(dataloader):
            # 清空梯度
            optimizer.zero_grad()
            # 随机采样时间步
            t = torch.randint(0, 1000, (x_0.shape[0],))
            epsilon = torch.randn_like(x_0)

            # 一步生成 x_t , x_t = √ᾱ_t * x_0 + √(1-ᾱ_t) * ε
            x_t = (
                sqrt_alpha_bar[t].view(-1, 1, 1, 1) * x_0 +
                sqrt_one_minus_alpha_bar[t].view(-1, 1, 1, 1) * epsilon
            )

            epsilon_pred = model(x_t, t)
            loss = F.mse_loss(epsilon_pred, epsilon)
            loss.backward()
            optimizer.step()
</code></pre>
