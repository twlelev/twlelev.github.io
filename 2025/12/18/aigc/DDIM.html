<hr>
<h2 id="title-DDIM核心原理top-falsecover-falsetoc-truemathjax-truedate-2025-12-18-15-31-01password-summary-tags-AIGCcategories-AIGC"><a href="#title-DDIM核心原理top-falsecover-falsetoc-truemathjax-truedate-2025-12-18-15-31-01password-summary-tags-AIGCcategories-AIGC" class="headerlink" title="title: DDIM核心原理top: falsecover: falsetoc: truemathjax: truedate: 2025-12-18 15:31:01password:summary:tags:  - AIGCcategories:  - AIGC"></a>title: DDIM核心原理<br>top: false<br>cover: false<br>toc: true<br>mathjax: true<br>date: 2025-12-18 15:31:01<br>password:<br>summary:<br>tags:<br>  - AIGC<br>categories:<br>  - AIGC</h2><h2 id="DDPM与DDIM区别"><a href="#DDPM与DDIM区别" class="headerlink" title="DDPM与DDIM区别"></a>DDPM与DDIM区别</h2><p> DDPM 假设反向过程是一个马尔可夫链，反向采样必须一步步迭代，$x_{t-1}$ 只依赖于前一步 $x_t$。</p>
<p>DDIM将扩散过程从马尔科夫链推广到非马尔科夫链。同样的训练模型，采样时可以从 1000 步跳到 50 步，速度提升 20 倍，且质量几乎不打折扣。</p>
<h2 id="DDIM原理"><a href="#DDIM原理" class="headerlink" title="DDIM原理"></a>DDIM原理</h2><p>DDIM 的核心观察是：__训练模型时，我们其实只关心每一个边缘分布 $q(x_t|x_0)$ 是否符合高斯分布，而不必关心它们之间是如何演化的。</p>
<h4 id="A-共享的边缘分布"><a href="#A-共享的边缘分布" class="headerlink" title="A. 共享的边缘分布"></a>A. 共享的边缘分布</h4><p>DDIM 重新设计了一个推理过程，它满足以下两个性质：</p>
<ol>
<li>__边缘分布一致__：对于任何 $t$，其 $q(x_t|x_0)$ 与 DDPM 完全相同（即 $\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon$）。</li>
<li>_<em>非马尔可夫性__：$x_t$ 的生成可以依赖于 $x_0$ 和 $x</em>{t-1}$ 等更多信息。</li>
</ol>
<h4 id="B-核心公式推导"><a href="#B-核心公式推导" class="headerlink" title="B. 核心公式推导"></a>B. 核心公式推导</h4><p>DDIM 定义了一个新的条件分布 $q_\sigma(x_{t-1} | x_t, x_0)$： $$x_{t-1} &#x3D; \sqrt{\bar{\alpha}<em>{t-1}} \underbrace{\left( \frac{x_t - \sqrt{1-\bar{\alpha}<em>t} \epsilon_\theta(x_t)}{\sqrt{\bar{\alpha}<em>t}} \right)}</em>{\text{预测的 } x_0} + \underbrace{\sqrt{1-\bar{\alpha}</em>{t-1} - \sigma_t^2} \cdot \epsilon_\theta(x_t)}</em>{\text{指向 } x_t \text{ 的方向}} + \underbrace{\sigma_t \epsilon_t}_{\text{随机噪声}}$$</p>
<p>重新定义 $x_{t-1}$_<em>：DDIM 认为，$x</em>{prev}$（注意这里不是相邻的 $t-1$，而是子序列中的前一个步长）可以通过以下三部分的线性组合得到：</p>
<ul>
<li>__指向 $x_0$ 的分量__：由 $\hat{x}_0$ 确定。</li>
<li>__指向 $x_t$ 的方向分量__：利用 $\epsilon_\theta$ 确保它依然在当前的扩散路径上。</li>
<li>__随机噪声分量__：由 $\sigma$ 控制。</li>
</ul>
<p>在这个公式中，$\sigma_t$ 是一个可调参数：</p>
<ul>
<li>当 $\sigma_t^2 &#x3D; \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \cdot \beta_t$ 时，__DDIM 退化回 DDPM__（马尔可夫随机采样）。</li>
<li>当 <strong>$\sigma_t &#x3D; 0$</strong> 时，过程变得完全确定 (Deterministic)__。此时的过程被称为 DDIM，它实际上是在解一个常微分方程 (ODE)。</li>
</ul>
<h4 id="C-为什么能跳步"><a href="#C-为什么能跳步" class="headerlink" title="C. 为什么能跳步?"></a>C. 为什么能跳步?</h4><p>DDIM 的公式定义的是 $x_{t-1}$ 如何由 $x_t$ 和 $x_0$ 组成，而这个 $t$ 和 $t-1$ __并不一定要是相邻的整数__。</p>
<h4 id="D-为什么训练好的-DDPM-模型可以直接用-DDIM"><a href="#D-为什么训练好的-DDPM-模型可以直接用-DDIM" class="headerlink" title="D. 为什么训练好的 DDPM 模型可以直接用 DDIM?"></a>D. 为什么训练好的 DDPM 模型可以直接用 DDIM?</h4><p>因为它们的优化目标（Loss Function）是完全一样的。</p>
